# Beberapa fungsi dasar untuk memudahkan pengerjaan

from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support
import matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import numpy as np
import itertools
import datetime
import zipfile
import os

# Fungsi untuk mengimport dan mengatur ukuran gambar sebagai input model


def upload_and_resize_image(filename, img_shape=224, scale=True):
    """
    Membaca gambar berdasarkan nama file, kemudian mengubahnya menjadi tensor dan mengatur ukurannya secara default (224, 224, 3).

    Parameters
    ----------
    filename (str): string filename dari gambar
    img_shape (int): size target gambar, default 224
    scale (bool): mengatur ukuran piksel dalam rentang (0, 1), default True
    """
    # Membaca gambar
    img = tf.io.read_file(filename)
    # Decode gambar menjadi tensor
    img = tf.image.decode_jpeg(img, channels=3)
    # Resize ukurang ambar
    img = tf.image.resize(img, [img_shape, img_shape])
    if scale:
        # Rescale the image (mendapatkan nilai 0 dan 1)
        return img/255.
    else:
        return img


# Fungsi untuk melakukan plot confusion matriks
def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False):
    """
    Membuat suatu confusion matriks berlabel kemudian membandingkan hasil prediksi dan nilai label sebenarnya. 

    Jika diberikan label class, confusion matriks akan memiliki label, apabila tidak, nilai integer yang akan digunakan.

    Args:
      y_true: Array dari label sebenarnya (harus berukuran serupa dengan y_pred).
      y_pred: Array dari label prediksi (harus berukuran serupa dengan y_true).
      classes: Array dari label class (dalam string). Jika `None`, label integer yang digunakan.
      figsize: Ukuran tabel confusion matriks (default=(10, 10)).
      text_size: Mengatur ukuran figure teks (default=15).
      norm: Menormalisasi nilai atau tidak (default=False).
      savefig: Menyimpan confusion matriks ke dalam file (default=False)

    Returns:
      Melakukan plotting confusion matriks dengan membandingkan y_true dan y_pred.

    Contoh penggunaan:
      make_confusion_matrix(y_true=test_labels, # label sebenarnya
                            y_pred=y_preds, # label prediksi
                            classes=classs_names, # array dari label kelas
                            figsize=(12, 12),
                            text_size=10)
    """
    # Membuat confusion matriks
    cm = confusion_matrix(y_true, y_pred)
    # Melakukan normalisasi
    cm_norm = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis]
    n_classes = cm.shape[0]  # Menentukan jumlah class yang diuji

    # Membuat plot confusion matriks
    fig, ax = plt.subplots(figsize=figsize)
    cax = ax.matshow(cm, cmap=plt.cm.Oranges)  # Semakin gelap, semakin baik
    fig.colorbar(cax)

    # Apakah ditemukan list class
    if classes:
        labels = classes
    else:
        labels = np.arange(cm.shape[0])

    # Melabeli axes
    ax.set(title="Confusion Matrix",
           xlabel="Predicted label",
           ylabel="True label",
           xticks=np.arange(n_classes),
           yticks=np.arange(n_classes),
           xticklabels=labels,
           yticklabels=labels)

    # Membuat x-axis labels muncul dibagian bawah
    ax.xaxis.set_label_position("bottom")
    ax.xaxis.tick_bottom()

    # Mengatur threshold untuk pewarnaan perbeda
    threshold = (cm.max() + cm.min()) / 2.

    # Plot text pada setiap sel
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        if norm:
            plt.text(j, i, f"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%",
                     horizontalalignment="center",
                     color="white" if cm[i, j] > threshold else "black",
                     size=text_size)
        else:
            plt.text(j, i, f"{cm[i, j]}",
                     horizontalalignment="center",
                     color="white" if cm[i, j] > threshold else "black",
                     size=text_size)

    # Menyimpan konfigursi pada chdir
    if savefig:
        fig.savefig("confusion_matrix.png")


# Fungsi untuk melakukan prediksi gambar dan membuat plot dari gambar tersebut (Untuk multi-class classification)
def pred_and_plot(model, filename, class_names):
    """
    Mengimport gambar berdasarkan filename, selanjutnya membuat prediksi didasarkan
    model latih selanjutnya membuat plot dari gambar yang diprediksi sebagai judul
    """
    # Mengimport target gambar dan memprosesnya
    img = upload_and_resize_image(filename)

    # Membuat prediksi
    pred = model.predict(tf.expand_dims(img, axis=0))

    # Mendata predicted class
    if len(pred[0]) > 1:  # Memeriksa multi-class
        # Jika lebih dari satu output, diambil prediksi tertinggi
        pred_class = class_names[pred.argmax()]
    else:
        # Jika hanya ada satu output, dilakukan pembulatan
        pred_class = class_names[int(tf.round(pred)[0][0])]

    # Plot gambar dan hasil prediksi
    plt.imshow(img)
    plt.title(f"Prediction: {pred_class}")
    plt.axis(False)


# Membuat tensorboard callback


def create_tensorboard_callback(dir_name, experiment_name):
    """
    Membuat sebuah callback TensorBoard untuk menyimpan data log files.

    Menyimpan log files ke dalam filepath:
        "dir_name/experiment_name/current_datetime/"

    Args:
      dir_name: directory target untuk menyimpan log files TensorBoard
      experiment_name: Nama direktori eksperiment (misal efficientnet_model_1)
    """
    log_dir = dir_name + "/" + experiment_name + "/" + \
        datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
    tensorboard_callback = tf.keras.callbacks.TensorBoard(
        log_dir=log_dir
    )

    print(f"Log files TensorBoard tersimpan di: {log_dir}")
    return tensorboard_callback


# Menampilkan kurva training dan validasi data
def plot_loss_curves(history):
    """
    Menampilkan accuracy dan loss curves untuk metrics training dan validation secara terpisah

    Args:
      history: TensorFlow model History object (lihat: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)
    """
    loss = history.history["loss"]
    val_loss = history.history["val_loss"]

    accuracy = history.history["accuracy"]
    val_accuracy = history.history["val_accuracy"]

    epochs = range(len(history.history["loss"]))

    # Plot loss
    plt.plot(epochs, loss, label="training_loss")
    plt.plot(epochs, val_loss, label="val_loss")
    plt.title("Loss")
    plt.xlabel("Epochs")
    plt.legend()

    # Plot accuracy
    plt.figure()
    plt.plot(epochs, accuracy, label="training_accuracy")
    plt.plot(epochs, val_accuracy, label="val_accuracy")
    plt.title("Accuracy")
    plt.xlabel("Epochs")
    plt.legend()


# Melakukan perbandingan history plot untuk fine-tuning
def compare_history_plot(original_history, new_history, initial_epochs=5):
    """
    Memabndingkan dua buah TensorFlow model History objects.

    Args:
      original_history: History object dari model asli (sebelum new_history)
      new_history: History  object dari model training berkelanjutan (setelah original_history)
      initial_epochs: Jumlah epochs dari original_history (new_history dimulai dari titik ini)
    """
    # Mendapatkan original history
    acc = original_history.history["accuracy"]
    loss = original_history.history["loss"]

    val_acc = original_history.history["val_accuracy"]
    val_loss = original_history.history["val_loss"]

    # Mengabungkan original history dengan new history
    total_acc = acc + new_history.history["accuracy"]
    total_loss = loss + new_history.history["loss"]

    total_val_acc = val_acc + new_history.history["val_accuracy"]
    total_val_loss = val_loss + new_history.history["val_loss"]

    # Membuat plots
    plt.figure(figsize=(8, 8))
    plt.subplot(2, 1, 1)
    plt.plot(total_acc, label="Training Accuracy")
    plt.plot(total_val_acc, label="Validation Accuracy")
    plt.plot([initial_epochs-1, initial_epochs-1],
             plt.ylim(), label="Start Fine Tuning")  # Reshift plot diantara epochs
    plt.legend(loc="lower right")
    plt.title("Training and Validation Accuracy")

    plt.subplot(2, 1, 2)
    plt.plot(total_loss, label="Training Loss")
    plt.plot(total_val_loss, label="Validation Loss")
    plt.plot([initial_epochs-1, initial_epochs-1],
             plt.ylim(), label="Start Fine Tuning")  # Reshift plot diantara epochs
    plt.legend(loc="upper right")
    plt.xlabel("Epochs")
    plt.title("Training and Validation Loss")
    plt.show()

    # Save dataframe into csv
    df_history = pd.DataFrame({"accuracy": total_acc, "loss": total_loss,
                               "val_acc": total_val_acc, "val_loss": total_val_loss})

    return df_history


# Fungsi untuk melakukan unzip zipfile pada chdir


def unzip_data(filename):
    """
    Melakukan unzip pada direktori saat ini

    Args:
      filename (str): lokasi file zip yang hendak diekstrak
    """
    zip_ref = zipfile.ZipFile(filename, "r")
    zip_ref.extractall()
    zip_ref.close()


# Fungsi untuk menghitung banyaknya data dimasing-masing direktori target
def walk_through_dir(dir_path):
    """
    Melakukan perhitungan banyaknya data pada direktori terkait

    Args:
      dir_path (str): direktori target

    Returns:
      Mencetak output untuk:
        jumlah subdirektori pada direktori target
        jumlah gambar (files) pada masing-masing subdirektori
    """
    for dirpath, dirnames, filenames in os.walk(dir_path):
        print(
            f"Terdapat {len(dirnames)} direktori dan {len(filenames)} gambar di '{dirpath}'.")


# Fungsi untuk melakukan perhitungan evaluasi
def calculate_results(y_true, y_pred):
    """
    Menghitung nilai accuracy, precision, recall, dan f1-score dari model

    Args:
      y_true: label sebenarnya tersusun dari 1D array
      y_pred: label prediksi tersusun dari 1D array

    Menampilkan nilai accuracy, precision, recall, f1-score ke dalam dictionary
    """
    model_accuracy = accuracy_score(y_true, y_pred) * 100
    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(
        y_true, y_pred, average="weighted")
    model_results = {"accuracy": model_accuracy,
                     "precision": model_precision,
                     "recall": model_precision,
                     "f1-score": model_f1}
    return model_results


# Mendapatkan nilai TP, TN, FP, FN dari masing-masing kelas di multiclass
def get_measure_each_class(y_actual, y_pred):
    class_id = set(y_actual).union(set(y_pred))
    TP = []
    FP = []
    TN = []
    FN = []

    for index ,_id in enumerate(class_id):
        TP.append(0)
        FP.append(0)
        TN.append(0)
        FN.append(0)
        for i in range(len(y_pred)):
            if y_actual[i] == y_pred[i] == _id:
                TP[index] += 1
            if y_pred[i] == _id and y_actual[i] != y_pred[i]:
                FP[index] += 1
            if y_actual[i] == y_pred[i] != _id:
                TN[index] += 1
            if y_pred[i] != _id == y_actual[i]:
                FN[index] += 1


    return list(class_id),TP, FP, TN, FN


def class_accuracy(TP, FP, TN, FN):
    return (TP+TN)/(TP+FP+FN+TN)  


def class_sensitivity(TP, FP, TN, FN): # Recall
    return TP/(TP+FN)


def class_specificity(TP, FP, TN, FN):
    return TN/(TN+FP)


def class_precision(TP, FP, TN, FN):
    return TP/(TP+FP)


def class_fpr(TP, FP, TN, FN):
    return FP/(FP+TN)